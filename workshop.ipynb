{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "260c0176-341b-4a25-899d-3ede85e01009",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Import Data\n",
    "In order to train our model, we are going to import time series data of room temperature.\n",
    "\n",
    "With our RNN, we are going to try to forecast the temperature of a room given a certain air flow temperature.\n",
    "\n",
    "You can find this dataset here: https://www.kaggle.com/datasets/vitthalmadane/ts-temp-1/data?select=MLTempDataset.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7df5fc72-8fc1-4b6a-b33c-c2934f5250f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/noah/.cache/kagglehub/datasets/vitthalmadane/ts-temp-1/versions/2\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version of dataset to local filesystem\n",
    "path = kagglehub.dataset_download(\"vitthalmadane/ts-temp-1\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395ffddd-d9d5-407b-8d68-0663c5b57c00",
   "metadata": {},
   "source": [
    "## Read Data into Memory\n",
    "For this workshop, we are going to use pandas to read the data into memory and convert it into a numpy array to train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20031837-ed90-45f1-92c0-c5a99a4882dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "file_path = os.path.join(path, 'MLTempDataset.csv')\n",
    "temperature_data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f70790c-33f2-493a-ae8a-cd4c30e3f317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 6676 entries, 0 to 6675\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  6676 non-null   int64  \n",
      " 1   Datetime1   6676 non-null   int64  \n",
      " 2   DAYTON_MW   6676 non-null   float64\n",
      " 3   Datetime    6676 non-null   str    \n",
      "dtypes: float64(1), int64(2), str(1)\n",
      "memory usage: 208.8 KB\n"
     ]
    }
   ],
   "source": [
    "temperature_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd30511c-884c-4348-97bb-c98614813239",
   "metadata": {},
   "source": [
    "## Data Visualization\n",
    "\n",
    "In order to train our model, we need to understand what we are training the model on.\n",
    "\n",
    "If we look at the top 5 rows of our temperature data, we are given 4 columns:\n",
    "\n",
    "1. Unnamed: This represents the index of the data, since our data is in order, we can ignore this.\n",
    "2. Datetime1: This is the hour of the day between 0 and 23\n",
    "3. DAYTON_MW: This is the temperature of the room in Celsius\n",
    "4. Datetime: This is the Date and hour of the day in a Datetime Format\n",
    "\n",
    "We want our model to forecast temperature over time. So, we will treat our temperature as our label and we will Datetime as the time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87e63692-bfe5-4700-93dd-7b46bbf9a464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Datetime1</th>\n",
       "      <th>DAYTON_MW</th>\n",
       "      <th>Datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.867</td>\n",
       "      <td>2022-01-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21.000</td>\n",
       "      <td>2022-01-04 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20.867</td>\n",
       "      <td>2022-01-04 02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>20.650</td>\n",
       "      <td>2022-01-04 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>20.400</td>\n",
       "      <td>2022-01-04 04:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Datetime1  DAYTON_MW             Datetime\n",
       "0           0          0     20.867  2022-01-04 00:00:00\n",
       "1           1          1     21.000  2022-01-04 01:00:00\n",
       "2           2          2     20.867  2022-01-04 02:00:00\n",
       "3           3          3     20.650  2022-01-04 03:00:00\n",
       "4           4          4     20.400  2022-01-04 04:00:00"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d183b6d-eae2-42de-b478-5886d4a1c1f4",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "Continuing with the data aspect of machine learning, we need to preprocess our data in a way that facilitates training for time series data.\n",
    "\n",
    "As part of this, we will need to standardize our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3328713e-48a1-4c1f-8405-f8f2005ce645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 20.867, '2022-01-04 00:00:00'],\n",
       "       [1, 1, 21.0, '2022-01-04 01:00:00'],\n",
       "       [2, 2, 20.867, '2022-01-04 02:00:00'],\n",
       "       ...,\n",
       "       [6673, 21, 26.45, '2022-10-09 01:00:00'],\n",
       "       [6674, 22, 25.9, '2022-10-09 02:00:00'],\n",
       "       [6675, 23, 25.567, '2022-10-09 03:00:00']],\n",
       "      shape=(6676, 4), dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert pandas data to numpy for training\n",
    "temperature_data = temperature_data.to_numpy()\n",
    "temperature_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb66eb47-04bd-4c04-8576-098d74c30e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to create dataset\n",
    "# Basically, we are saying, take 60 sequential temperatures, then, given this information\n",
    "# predict what the next temperature would be.\n",
    "def create_dataset(data, time_step=60):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - time_step - 1):\n",
    "        X.append(data[i:(i + time_step), 2])\n",
    "        y.append(data[i + time_step, 2])\n",
    "    return np.array(X).astype('float64'), np.array(y).astype('float64')\n",
    "\n",
    "# X, y = create_dataset(temperature_data)\n",
    "# X = X.reshape(X.shape[0], X.shape[1], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c703cfb1-69d9-4f71-a9f2-3e13bcb3a536",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_dataset(temperature_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "644964fa-65bb-4365-bd69-100b28528733",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(X.shape[0], X.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d10e920-3994-40a1-9d1f-4a8e8b0e2d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018a76e1-399a-4f57-95ba-878ddc39e3b8",
   "metadata": {},
   "source": [
    "# Build the Model\n",
    "\n",
    "Using Tensorflow and Keras, we are going to build a Recurrent Nueral Network to forecast room temperature. In particular, we are going to use a Gated Recurrent Unit Model. \n",
    "\n",
    "At a high level, this addresses the vanishing gradient problem, allowing them to reliably predict over longer periods of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "707299c1-fa5d-47bf-b24e-44ce028e7bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-26 22:37:22.623044: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-01-26 22:37:22.650644: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-01-26 22:37:23.204242: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1769485043.656707   76119 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1258 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, GRU\n",
    "model = Sequential([\n",
    "    # GRU(64, activation='tanh', return_sequences=True, input_shape=(10, 5)),  # First GRU layer\n",
    "    GRU(64, activation='tanh'),  # Second GRU layer\n",
    "    Dense(1)  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['r2_score'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb73fbc-fbbe-4fcd-a2d0-5c8fd5023746",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "Now, we are going to train our model to fit our data and hopefully get a descent temperature forecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30724025-7dea-48cf-9634-015792a42810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-26 22:37:24.383998: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 280.0976 - r2_score: -4.3851\n",
      "Epoch 2/20\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 101.0410 - r2_score: -0.9426\n",
      "Epoch 3/20\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 57.6578 - r2_score: -0.1085\n",
      "Epoch 4/20\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 33.7979 - r2_score: 0.3502\n",
      "Epoch 5/20\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 22.3633 - r2_score: 0.5700\n",
      "Epoch 6/20\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 16.6705 - r2_score: 0.6795\n",
      "Epoch 7/20\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 13.6076 - r2_score: 0.7384\n",
      "Epoch 8/20\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.9246 - r2_score: 0.7707\n",
      "Epoch 9/20\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.8340 - r2_score: 0.7917\n",
      "Epoch 10/20\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 10.1604 - r2_score: 0.8047\n",
      "Epoch 11/20\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 9.6791 - r2_score: 0.8139\n",
      "Epoch 12/20\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 9.3132 - r2_score: 0.8209\n",
      "Epoch 13/20\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 9.0442 - r2_score: 0.8261\n",
      "Epoch 14/20\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.9006 - r2_score: 0.8289\n",
      "Epoch 15/20\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.6777 - r2_score: 0.8332\n",
      "Epoch 16/20\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.5450 - r2_score: 0.8357\n",
      "Epoch 17/20\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 8.4668 - r2_score: 0.8372\n",
      "Epoch 18/20\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 8.4350 - r2_score: 0.8378\n",
      "Epoch 19/20\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 8.3336 - r2_score: 0.8398\n",
      "Epoch 20/20\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.2608 - r2_score: 0.8412\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=20, batch_size=64)\n",
    "\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14612461-7077-45ce-ae54-2e266156cb7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 - 0s - 8ms/step - loss: 3.0048 - r2_score: 0.8580\n",
      "\n",
      "Test accuracy: 0.8579612970352173\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0926944b-7696-4359-bb99-4d41dcee61a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24.038025],\n",
       "       [24.225903],\n",
       "       [24.945562],\n",
       "       [25.326895],\n",
       "       [25.249283],\n",
       "       [12.122084],\n",
       "       [10.242821],\n",
       "       [10.996746],\n",
       "       [17.140553],\n",
       "       [12.288088]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.predict(X_train, verbose=0)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58f5ddb3-8d68-475f-951b-f9da2928ad21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24.867, 25.5  , 26.   , 26.267,  9.633,  9.267,  8.85 , 15.6  ,\n",
       "       12.267,  9.067])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10].transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fdc5f4-15d6-4e3d-bd3f-ecd598e42550",
   "metadata": {},
   "source": [
    "## Exporting the model\n",
    "At this point, we have a satisfactory model. At this point, we are going to export this model to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed2944b8-6faa-41c4-901a-9090e1b79ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘models’: File exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "!mkdir models\n",
    "model.save('models/my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72475e1e-f959-4404-b9fe-01237b2aa71d",
   "metadata": {},
   "source": [
    "## Optimization\n",
    "There are techniques that we can use to reduce the size of Nueral Networks to reduce their size\n",
    "and their computational cost.\n",
    "\n",
    "Some of these include:\n",
    "1. Weight Pruning\n",
    "2. Quantization\n",
    "3. Weight Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0922046d-0bd5-42a8-9b8a-2997851516be",
   "metadata": {},
   "source": [
    "## Quantization\n",
    "Quantization aware training emulates inference-time quantization, creating a model that downstream tools will use to produce actually quantized models. The quantized models use lower-precision (e.g. 8-bit instead of 32-bit float), leading to benefits during deployment.\n",
    "\n",
    "### Deploy with quantization\n",
    "\n",
    "Quantization brings improvements via model compression and latency reduction. With the API defaults, the model size shrinks by 4x, and we typically see between 1.5 - 4x improvements in CPU latency in the tested backends. Eventually, latency improvements can be seen on compatible machine learning accelerators, such as the EdgeTPU and NNAPI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318ebefb-85b4-4a52-8f2d-37e31afa9eb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
